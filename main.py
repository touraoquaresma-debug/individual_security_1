import msvcrt  # Biblioteca para verificar se uma tecla foi pressionada
import time

import cv2
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress
from rich.prompt import Confirm, Prompt
from rich.table import Table
from ultralytics import YOLO

from constants import (
    ARQUIVO_PESOS,
    ARQUIVO_VIDEO_PADRAO,
    CLASSES_DETECTADAS,
    DURACAO_PADRAO,
    POSE_NAO_DETECTADA,
)

console = Console()


def get_user_parameters():
    console.print(
        Panel('ğŸ® ConfiguraÃ§Ã£o do Monitoramento', style='bold green')
    )

    # SeleÃ§Ã£o da fonte de vÃ­deo
    video_source = Prompt.ask(
        '\nğŸ“¹ Escolha a fonte de vÃ­deo',
        choices=['webcam', 'arquivo'],
        default='webcam',
    )

    video_path = (
        '0'
        if video_source == 'webcam'
        else Prompt.ask(
            'ğŸ¥ Digite o caminho do arquivo de vÃ­deo',
            default=ARQUIVO_VIDEO_PADRAO,
        )
    )

    # SeleÃ§Ã£o da duraÃ§Ã£o
    duration_str = Prompt.ask(
        '\nâ±ï¸ Digite a duraÃ§Ã£o desejada em minutos', default='5'
    )
    duration_seconds = float(duration_str) * 60

    # SeleÃ§Ã£o do arquivo de pesos
    use_default_weights = Confirm.ask(
        '\nğŸ¯ Usar arquivo de pesos padrÃ£o?', default=True
    )
    weights_path = (
        ARQUIVO_PESOS
        if use_default_weights
        else Prompt.ask(
            'Digite o caminho para o arquivo de pesos personalizado'
        )
    )

    # SeleÃ§Ã£o da visualizaÃ§Ã£o dos frames
    annotated_frame_cv2 = Confirm.ask(
        '\nğŸ–¼ï¸ Visualizar frames com anotaÃ§Ãµes?', default=True
    )

    return video_path, duration_seconds, weights_path, annotated_frame_cv2


def run_pose_monitoring(  # noqa: PLR0912, PLR0914, PLR0915
    video_path=ARQUIVO_VIDEO_PADRAO,
    duration_seconds=DURACAO_PADRAO,
    weights_path=ARQUIVO_PESOS,
    annotated_frame_cv2=True,
):
    # InicializaÃ§Ã£o do monitoramento
    console.print(
        Panel('ğŸ¥ Sistema de Monitoramento de Poses', style='bold blue')
    )

    start_time = time.time()
    pose_durations = {
        'idoso deitado': 0,
        'idoso em pe': 0,
        'idoso sentado': 0,
        'jovem': 0,
        POSE_NAO_DETECTADA: 0,
    }
    frame_count = 0

    # Carregamento do modelo YOLO
    with console.status('[bold green]Carregando o modelo YOLO...'):
        try:
            model = YOLO(weights_path)
            model.classes = [0, 1, 2, 3]
        except Exception as e:
            console.print(
                f'[bold red]âŒ Erro ao carregar o modelo:[/] {str(e)}'
            )
            return

    # InicializaÃ§Ã£o da cÃ¢mera ou vÃ­deo
    cap = cv2.VideoCapture(0 if video_path == '0' else video_path)
    if not cap.isOpened():
        console.print('[bold red]âŒ Erro ao abrir fonte de vÃ­deo!')
        return

    console.print('\nğŸ“Š ConfiguraÃ§Ãµes:')
    console.print(f'- DuraÃ§Ã£o planejada: {duration_seconds / 60:.1f} minutos')
    console.print(
        '- Classes detectadas:'
        + f' {[CLASSES_DETECTADAS[c] for c in model.classes]}'
    )

    # Processamento dos frames
    with Progress(console=console) as progress:
        task = progress.add_task(
            '[cyan]Processando frames...[/cyan] [yellow]'
            + '(Pressione q para terminar)[/yellow]',
            total=duration_seconds,
        )

        while cap.isOpened():
            current_time = time.time()
            elapsed = current_time - start_time

            # Atualiza a barra de progresso baseada no tempo real
            progress.update(task, completed=min(elapsed, duration_seconds))

            # Verifica se atingiu o tempo desejado
            if elapsed >= duration_seconds:
                break

            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1

            results = model(frame, verbose=False)[
                0
            ]  # ObtÃ©m o primeiro resultado
            person_detected = False
            best_confidence = 0
            best_pose = POSE_NAO_DETECTADA

            if annotated_frame_cv2:
                # Adiciona as anotaÃ§Ãµes ao frame
                annotated_frame = results.plot()

                # Mostra o frame com as anotaÃ§Ãµes na tela
                cv2.imshow(
                    'Sistema de Monitoramento de '
                    + 'Poses - Deteccao em Tempo Real',
                    annotated_frame,
                )

                # tecla a ser pressionada na janela
                # do openvc para quebrar o loop
                key = cv2.waitKey(1) & 0xFF
                # Verifica se a tecla q foi pressionada na janela do OpenCV
                if key == ord('q'):
                    console.print(
                        '\nâŒ Monitoramento interrompido'
                        + ' pela janela do OpenCV.'
                    )
                    break

            # Verifica se hÃ¡ tecla pressionada no terminal
            if msvcrt.kbhit():
                terminal_key = msvcrt.getch().decode().lower()
                if terminal_key == 'q':
                    console.print(
                        '\nâŒ Monitoramento interrompido pelo terminal.'
                    )
                    break

            for detection in results.boxes.data:
                class_id = int(
                    detection[5]
                )  # O Ã­ndice da classe estÃ¡ na posiÃ§Ã£o 5
                confidence = float(
                    detection[4]
                )  # A confianÃ§a estÃ¡ na posiÃ§Ã£o 4

                if class_id in CLASSES_DETECTADAS:
                    person_detected = True
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_pose = CLASSES_DETECTADAS[class_id]

            detected_pose_this_frame = (
                best_pose if person_detected else POSE_NAO_DETECTADA
            )
            pose_durations[detected_pose_this_frame] += 1

    # FinalizaÃ§Ã£o e relatÃ³rio
    cap.release()
    cv2.destroyAllWindows()
    end_time = time.time()
    total_time = end_time - start_time

    # CriaÃ§Ã£o do relatÃ³rio em tabela
    table = Table(title='ğŸ“Š RelatÃ³rio de Monitoramento de Poses')
    table.add_column('Pose', style='cyan')
    table.add_column('DuraÃ§Ã£o (min)', justify='right')
    table.add_column('Porcentagem', justify='right')

    # Calcular a proporÃ§Ã£o de tempo para cada pose
    total_frames = sum(pose_durations.values())
    for pose, frames in pose_durations.items():
        # Calcula a proporÃ§Ã£o do tempo total para cada pose
        duration_minutes = (frames / total_frames) * (total_time / 60)
        percentage = (frames / total_frames) * 100 if total_frames > 0 else 0
        table.add_row(pose, f'{duration_minutes:.2f}', f'{percentage:.1f}%')

    console.print('\n')
    console.print(table)
    console.print(
        '\nâ±ï¸ Tempo total monitorado: [bold]'
        + f'{total_time / 60:.2f}[/] minutos'
    )
    console.print(
        f'âš¡ Tempo de processamento: [bold]{total_time:.2f}[/] segundos'
    )

    return pose_durations


if __name__ == '__main__':
    try:
        while True:
            console.clear()
            console.print(
                Panel(
                    'ğŸ¤– Sistema de Monitoramento de Poses',
                    style='bold magenta',
                )
            )

            start_monitoring = Confirm.ask(
                '\nğŸš€ Iniciar novo monitoramento?', default=True
            )
            if not start_monitoring:
                console.print('\nğŸ‘‹ AtÃ© logo!', style='bold blue')
                break

            video_path, duration_seconds, weights_path, annotated_frame_cv2 = (
                get_user_parameters()
            )

            console.print('\nâœ¨ Iniciando monitoramento com as configuraÃ§Ãµes:')
            console.print(f'ğŸ“¹ Fonte de vÃ­deo: {video_path}')
            console.print(f'â±ï¸ DuraÃ§Ã£o: {duration_seconds / 60:.1f} minutos')
            console.print(f'ğŸ¯ Arquivo de pesos: {weights_path}')

            if Confirm.ask('\nâ–¶ï¸ Confirmar e comeÃ§ar?', default=True):
                report = run_pose_monitoring(
                    video_path,
                    duration_seconds,
                    weights_path,
                    annotated_frame_cv2,
                )

            if not Confirm.ask(
                '\nğŸ”„ Deseja realizar outro monitoramento?', default=True
            ):
                console.print('\nğŸ‘‹ AtÃ© logo!', style='bold blue')
                break

    except KeyboardInterrupt:
        console.print(
            '\n\nâŒ Monitoramento interrompido pelo usuÃ¡rio', style='bold red'
        )
    except Exception as e:
        console.print(f'\n\nâŒ Erro inesperado: {str(e)}', style='bold red')
